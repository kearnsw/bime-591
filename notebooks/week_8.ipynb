{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "Please install the following packages\n",
    "\n",
    "`pip3 install scikit-learn`\n",
    "\n",
    "`pip3 install tensorflow`\n",
    "\n",
    "`pip3 install matplotlib`\n",
    "\n",
    "`pip3 install gym`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocastic Gradient Descent\n",
    "\n",
    "Suppose there was some true function: $y = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + w_{4}x_{4} + w_{5}x_{5}$. We create random weights for this fuction, and try to find them through SGD. Go ahead and change the true weights! See what happens when you change the learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_weights = np.array([20, 300, 2, 3, 5])\n",
    "predicted_weights = np.zeros(len(true_weights))\n",
    "errors = []\n",
    "for i in range(100):\n",
    "    point = np.random.randint(0, 10, len(true_weights))\n",
    "\n",
    "    y_true = np.dot(point, true_weights)\n",
    "    y_predicted = np.dot(point, predicted_weights)\n",
    "\n",
    "    difference = y_predicted - y_true\n",
    "    errors.append((y_predicted - y_true)**2)\n",
    "\n",
    "    predicted_weights -= 0.01 * difference * point\n",
    "\n",
    "plt.figure(dpi = 150)\n",
    "plt.plot(errors)\n",
    "plt.title('Error Over Time')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Time Step')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Let's build a neural network to classify the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = (x_train.astype(float) - np.mean(x_train))/np.std(x_train)\n",
    "x_test = (x_test.astype(float) - np.mean(x_test))/np.std(x_test)\n",
    "\n",
    "for i in range(5):\n",
    "  plt.imshow(x_train[i])\n",
    "  plt.title(f'Handwritten {y_train[i]}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test= x_test.reshape(-1, 784)\n",
    "\n",
    "# one-hot encoding:\n",
    "encoder = OneHotEncoder(categories='auto')\n",
    "y_train = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test = encoder.fit_transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "nn = Sequential()\n",
    "nn.add(Dense(100, activation = 'relu'))\n",
    "nn.add(Dense(10, activation = 'softmax'))\n",
    "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = nn.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 3)\n",
    "print (nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 150)\n",
    "plt.plot(history.history['acc'], label = 'training')\n",
    "plt.plot(history.history['val_acc'], label = 'test')\n",
    "plt.title('Training History')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
